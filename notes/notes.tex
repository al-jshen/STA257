\documentclass[a4paper,10pt]{article}
\usepackage{geometry}
\usepackage{graphicx}
\graphicspath{ {./figures/} }
\usepackage{caption}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{amsmath,amsthm,amssymb,cancel,bm,upgreek}
\usepackage{floatrow}
\usepackage{lastpage}
\geometry{total={210mm,297mm},
left=25mm,right=25mm,%
bindingoffset=0mm, top=20mm,bottom=20mm}
\setlength{\parindent}{0pt}
\newcommand{\linia}{\rule{\linewidth}{0.5pt}}
\newcommand{\fig}[1]{\centerline{\includegraphics[width=0.6\columnwidth]{#1}}}
\newcommand{\ind}{\leavevmode{\parindent=1em\indent}}
\newcommand{\R}{\mathbb{R}}

\AtBeginDocument{%
  \setlength\abovedisplayskip{-3pt}
  \setlength\belowdisplayskip{5pt}}
   

% title configuration
\makeatletter
\def\@maketitle{%
\begin{center}
\hfill{\textit{Last modified \today}} \\
\vspace{1em}
{\huge \textsc{\@title}\par}
\vspace{1em}
\\
\linia\\
\vspace{1em}
\@author
\vspace{1em}
\end{center}
}
\makeatother

% header, footer configuration
\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\renewcommand{\headrulewidth}{0pt}
\lfoot{}
\cfoot{}
\rfoot{Page \thepage\ /\ \pageref{LastPage}}

\usepackage[hidelinks]{hyperref}

% --------------------------------------------- %
\begin{document}
\title{STA257: Probability and Statistics I\\
    \Large University of Toronto | Fall 2019}
\author{Jeff Shen}
\date{\today}
\maketitle
\tableofcontents


% --------------------------------------------- %
% Probability and Counting %
% --------------------------------------------- %

\newpage
\section{Probability and Counting}

\subsection{Introduction}

\textbf{Experiments}: situations wherre outcome is random. eg. flipping a coin is an experiment.

\textbf{Sample space}: set of all possible outcomes, denoted $S$ or $\Omega$. The number of elements in the sample space (cardinality) is denoted $|\Omega|$.

\textbf{Event}: a subset of a sample space.

\textbf{Outcome}: a particular element of a sample space $s_1 \in \Omega$.

\subsection{Set Theory}

\subsubsection{Definitions}

\begin{itemize}
    \item \textbf{union}: $A \cup B$. Elements in either $A$ or $B$.
    \item \textbf{intersection}: $A \cap B$. Elements in both $A$ and $B$. 
    \item \textbf{complement} of A: $A^c$. Elements not in $A$.
    \item \textbf{empty set}: $\varnothing$. Set with no elements in it. 
    \item $A$ and $B$ are \textbf{disjoint}: $A \cap B = \varnothing$. There are no elements in the intersection of $A$ and $B$.
\end{itemize}

\subsubsection{Laws of Set Theory} 

\begin{enumerate}
    \item \textbf{commutativity}: $A \cup B = B \cup A$, $A \cap B = B \cap A$
    \item \textbf{associativity}: $(A\cup B)\cup C = A\cup (B\cup C)$, $(A\cap B)\cap C = A\cap (B\cap B)$
    \item \textbf{distributivity}: $(A\cup B)\cap C = (A\cap C)\cup (B\cap C)$, $(A\cap B)\cup C = (A\cup C)\cap (B\cup C)$
\end{enumerate}

\subsection{Probability Measures}

\textbf{Probability measure}: a function which maps subsets of $\Omega$, which can be defined on any space, to real numbers $\R$.

\subsubsection{Axioms of Probability Measures}

\begin{itemize}
    \item $P(\Omega) = 1$
    \item $\forall A \in \Omega, P(A) \geq 0$
    \item if $A_1, A_2, \ldots A_n, \ldots$ are mutually disjoint, then $P(\bigcup_{i=1}^{\infty}A_i) = \sum_{i=1}^{\infty}P(A_i)$.
\end{itemize}

\subsubsection{Properties of Probability Measures}

\begin{itemize}
    \item $\forall A \in \Omega, P(A^c) = 1 - P(A)$

        Proof:

        \begin{align*}
            1 &= P(\Omega)\;&\text{by Axiom 1} \\
              &= P(A\cup A^c)\;&\text{by definition of complement} \\
              &= P(A) + P(A^c)\;&\text{by Axiom 3 (since $A, A^c$ are disjoint)} 
        \end{align*}

        Rearrange this to see that $P(A^c) = 1 - P(A)$. 

    \item $P(\varnothing) = 0$

        Proof: 

        \begin{align*}
            P(\Omega) &= P(\Omega \cup \varnothing)\;&\text{since $\Omega \cup \varnothing = \Omega$} \\
                      &= P(\Omega) + P(\varnothing)\;&\text{by Axiom 3 (since $\Omega, \varnothing$ are disjoint)}
        \end{align*}

        So $P(\varnothing) = 0$.

    \item For $A, B \subseteq \Omega, A \subseteq B \implies P(A) \leq P(B)$

        Proof:

        \begin{align*}
            P(B) &= P(A\cup (B\cap A^c)) \\
                 &= P(A) + P(B\cap A^c)\;&\text{by Axiom 3 (since $A, A^c$ are disjoint)}
        \end{align*}
        
        But note that $P(B\cap A^c) \geq 0$ by Axiom 2. 

        Then $P(B) = P(A) + P(B\cap A^c) \geq P(A)$. 

    \item For $A, B \subseteq \Omega, P(A\cup B) = P(A) + P(B) - P(A\cap B)$

        Proof:

        \ind Case 1: $A, B$ are disjoint. Then $A\cap B = \varnothing \implies P(A\cap B) = 0$. 

        \begin{align*}
            P(A\cup B) &= P(A) + P(B)\;&\text{by Axiom 3 (since $A, B$ are disjoint)} \\
                       &= P(A) + P(B) + P(A\cap B)\;&\text{since we can add 0 wherever we want}
        \end{align*}

        \ind Case 2: $A, B$ not disjoint. Then $A\cap B \neq \varnothing$.

        \ind \ind Let $C = A\cap B^c$, $D = A\cap B$, $E = A^c\cap B$. 

        \ind \ind Then $C, D, E$ are disjoint, and $A = C\cup D$, $B = D\cup E$, and $A\cup B = C\cup D\cup E$. 

        \fig{addition_law}
        
        \begin{align*}
            P(A) + P(B) - P(A\cap B) &= P(C\cup D) + P(D\cup E) - P(D)\;&\text{by how we defined $C, D, E$}\\
                                     &= P(C) + P(D) + P(D) + P(E) - P(D)\;&\text{by Axiom 3 and disjointness of $C, D, E$}\\
                                     &= P(C) + P(D) + P(E) \\
                                     &= P(C\cup D\cup E)\;&\text{by Axiom 3 and disjointness of $C, D, E$}\\
                                     &= P(A\cup B)
        \end{align*}
        

\subsection{Counting}

\textbf{Multiplication principle}: if there are $m$ ways to do one thing, and $n$ ways to do another thing, then there are $mn$ ways to do both things. 

\textbf{Permutation}: ordered arrangement of objects. 

\begin{itemize}
    \item Sampling \textbf{with replacement} means that duplicate item selection is allowed. (can pick the same object twice). For a set of size $n$ and a \textbf{sample size} (number of items selected) $r$, there are $n^r$ possible selections. 

    \item Sampling \textbf{without replacement} means that each item is selected once at most. For a set of size $n$ and a sample size $r$, there are $n(n-1)\ldots(n-r+1) = \frac{n!}{(n-r)!}$ possible selections. In particular, there are $n(n-1)\ldots(1)=n!$ ways to order $n$ elements. 
\end{itemize}

\textbf{Combination}: arrangement of objects {\em without regard to order}. Think about this as the ways to select objects without replacement, divided by the ways that those objects can be ordered. For a set of size $n$ and a sample size $r$, we express the combination as follows:

\begin{align*}
    {n\choose r} = \frac{n(n-1)\ldots(n-r+1)}{r!} = \frac{n!}{(n-r)!\,r!}
\end{align*}

\textbf{Binomial expansion}: 

\begin{align*}
    (a+b)^n = \sum_{k=0}^n{n\choose k}a^k\,b^{n-k}
\end{align*}

In particular, for $a=b=1$, 

\begin{align*}
    (1+1)^n = 2^n = \sum_{k=0}^n{n\choose k}(1)^k(1)^{n-k} = \sum_{k=0}^n{n\choose k}
\end{align*}

\subsection{Conditional Probability}



\subsection{Independence, Law of Total Probability}

\subsection{Equations}


% --------------------------------------------- %
% Random Variables %
% --------------------------------------------- %

\newpage
\section{Random Variables}

% --------------------------------------------- %
\subsection{Discrete Random Variables}

\subsubsection{Bernoulli}

\subsubsection{Binomial}

\subsubsection{Geometric}

\subsubsection{Negative Binomial}

\subsubsection{Hypergeometric}

\subsubsection{Poisson}


% --------------------------------------------- %
\subsection{Continuous Random Variables}

\subsubsection{Uniform}

\subsubsection{Exponential}

\subsubsection{Gamma}

\subsubsection{Beta}

\subsubsection{Uniform}

\subsubsection{Standard Normal}

\subsubsection{General Normal}

\subsection{Transformations of Random Variables}


% --------------------------------------------- %
% Expected Values %
% --------------------------------------------- %

\newpage
\section{Expected Values}

\subsection{Mean and Variance}
\subsubsection{LOTUS}
\subsubsection{Inequalities}

\subsection{Moment Generating Functions}


% --------------------------------------------- %
% Joint Distributions %
% --------------------------------------------- %

\newpage
\section{Joint Distributions}

\subsection{Joint and Marginal Distributions}
\subsubsection{Discrete}
\subsubsection{Continuous}

\subsection{Independence in Joint Distributions}

\subsection{Conditional Distributions}
\subsubsection{Discrete}
\subsubsection{Continuous}

\subsection{Functions of Joint Distributions}

\subsection{Order Statistics}

\end{document}
